{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Challenge Avazu Kaggle\n",
    "\n",
    "Auteur: Alphonse Doutriaux\n",
    "Date: février 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Préliminaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gzip\n",
    "import io\n",
    "import multiprocessing\n",
    "import matplotlib\n",
    "import datetime\n",
    "import joblib\n",
    "import pickle as pkl\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, log_loss, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import date, datetime\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Extraction d'un sample aléatoire de 1M de lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Extraction de lignes de manière aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line_count = 40428968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100000\n",
    "skip = sorted(random.sample(range(1,line_count + 1), line_count - n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.gz\", skiprows=skip, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# en cas d'extraction à garder\n",
    "df.to_csv(path_or_buf= './train_sample.csv', index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation des colonnes \"weekday\", \"hour\" et \"surface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weekday\n",
    "df[\"weekday\"] = df[\"hour\"].apply(lambda x: datetime.strptime(str(x), '%y%m%d%H').weekday())\n",
    "\n",
    "# Hour\n",
    "df[\"hour\"] = df[\"hour\"].apply(lambda x: int(str(x)[-2:]))\n",
    "\n",
    "# Surface\n",
    "df[\"area\"] = df[\"C15\"] * df[\"C16\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction d'un user_id et création de deux colonnes : fréquence d'apparition et nombre moyen de clics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'une colonne `User_freq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['User'] = df['device_id'] + df['device_ip'] + df['device_model'] #on crée une feature user \n",
    "values = df['User'].value_counts() # on remplace la valeur de user par sa fréquence d'apparition\n",
    "df['User_freq'] = df['User'].apply(lambda row: values[row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'une colonne `User_clicks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-f078ff735b08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'User'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'User_clicks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'User'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'click'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1e3\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for user in df['User']:\n",
    "    df['User_clicks'] = df[df['User'] == user]['click'].mean()\n",
    "    i=i+1\n",
    "    if i%1e3==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Séparation X et y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df[['click']]\n",
    "X = df[['C1', 'hour', 'banner_pos', 'site_category', 'app_category', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18', \n",
    "           'C19', 'C20','C21', 'area', 'weekday', 'User_freq']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation de la colonne C20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['C20'] = X['C20'].replace(-1, np.nan)\n",
    "X['C20'] = X['C20'].replace(np.nan, X['C20'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding avec get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_encode = ['device_type', 'device_conn_type', 'site_category', 'app_category', 'banner_pos', 'C18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full_columns = pd.read_csv(\"train.gz\", usecols=columns_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in columns_to_encode:\n",
    "    X[col] = X[col].astype('category', categories = df_full_columns[col].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=columns_to_encode, prefix = columns_to_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Préparation des folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "penalty = ['l1', 'l2']\n",
    "C = [0.05, 0.1, 0.5]\n",
    "\n",
    "param_grid = dict(penalty=penalty, \n",
    "                  C=C)\n",
    "\n",
    "lr_gs = GridSearchCV(LogisticRegression(), param_grid, n_jobs=-1, scoring = 'neg_log_loss', verbose = 2)\n",
    "grid_result_lr = lr_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lr_gs.best_score_)\n",
    "print(lr_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1',\n",
    "                        solver='liblinear',\n",
    "                        C=0.1,\n",
    "                        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[LibLinear][CV] ................................................. , total=   4.9s\n",
      "[LibLinear][CV] ................................................. , total=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    5.9s remaining:    8.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV] ................................................. , total=   6.1s\n",
      "[LibLinear][CV] ................................................. , total=   6.3s\n",
      "[LibLinear][CV] ................................................. , total=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.7s finished\n"
     ]
    }
   ],
   "source": [
    "lr_scores = cross_val_score(lr,\n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            cv=5, \n",
    "                            scoring=\"neg_log_loss\", \n",
    "                            n_jobs=-1, \n",
    "                            verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average log_loss: 43.30%\n",
      "Interval: [ 0.4114 ; 0.4546 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Average log_loss: {:.2%}\".format(-lr_scores.mean()))\n",
    "print(\"Interval: [\", round(-lr_scores.mean()-3*lr_scores.std(),4), \";\", round(-lr_scores.mean()+3*lr_scores.std(),4),\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = joblib.dump(lr, './models/lr.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grid search\n",
    "#learning_rate = [0.1, 0.15, 0.2]\n",
    "#n_estimators = [10]\n",
    "#colsample_bytree = [0.5, 0.7, 0.9]\n",
    "max_depth = [3, 5, 7]\n",
    "#reg_alpha = [0.1, 0.5, 1]\n",
    "#reg_lambda = [0.1, 0.5, 1]\n",
    "\n",
    "param_grid = dict(#learning_rate=learning_rate, \n",
    "                  #n_estimators=n_estimators, \n",
    "                  #colsample_bytree=colsample_bytree, \n",
    "                  max_depth=max_depth)\n",
    "                  #reg_alpha=reg_alpha,\n",
    "                  #reg_lambda=reg_lambda)\n",
    "\n",
    "xgb_gs = GridSearchCV(XGBClassifier(), param_grid, n_jobs=-1, scoring = 'neg_log_loss', verbose = 2)\n",
    "grid_result_xgb = xgb_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(xgb_gs.best_score_)\n",
    "print(xgb_gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Lancement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(verbose=2,\n",
    "                    n_jobs=-1,\n",
    "                    max_depth=4, \n",
    "                    learning_rate=0.2,\n",
    "                    colsample_bytree=0.9,\n",
    "                    n_estimators=600,\n",
    "                    reg_alpha=1,\n",
    "                    reg_lambda=1, \n",
    "                    objective='binary:logistic',\n",
    "                    booster='gbtree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=600,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=1, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1, verbose=2)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xgb_scores = cross_val_score(xgb,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             cv=5,\n",
    "                             scoring=\"neg_log_loss\",\n",
    "                             n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average log_loss: 80.78%\n",
      "Interval: [ -0.6594 ; 2.275 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Average log_loss: {:.2%}\".format(-xgb_scores.mean()))\n",
    "print(\"Interval: [\", round(-xgb_scores.mean()-3*xgb_scores.std(),4), \";\", round(-xgb_scores.mean()+3*xgb_scores.std(),4),\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = joblib.dump(xgb, './models/xgb.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RandomForests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.4s\n",
      "[CV] ................................................. , total=   0.5s\n",
      "[CV] ................................................. , total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "rf_scores = cross_val_score(rf,\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            cv=3,\n",
    "                            scoring=\"neg_log_loss\",\n",
    "                            n_jobs=-1,\n",
    "                            verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average log_loss: 166.53%\n",
      "Interval: [ 1.5398 ; 1.7908 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Average log_loss: {:.2%}\".format(-rf_scores.mean()))\n",
    "print(\"Interval: [\", round(-rf_scores.mean()-3*rf_scores.std(),4), \";\", round(-rf_scores.mean()+3*rf_scores.std(),4),\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = joblib.dump(rf, './models/rf.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = joblib.load(\"./models/lr.pkl\")\n",
    "xgb = joblib.load(\"./models/xgb.pkl\")\n",
    "rf = joblib.load(\"./models/rf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_preds = lr.predict_proba(X_test)\n",
    "xgb_preds = xgb.predict_proba(X_test)\n",
    "rf_preds = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_table = pd.DataFrame({\"LR\":lr_preds[:,1], \"XGBoost\":xgb_preds[:,1], \"RandomForests\":rf_preds[:,1]}, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] C=0.05, penalty=l1 ..............................................\n",
      "[CV] C=0.05, penalty=l1 ..............................................\n",
      "[CV] C=0.05, penalty=l1 ..............................................\n",
      "[CV] C=0.05, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.05, penalty=l1, total=   0.0s\n",
      "[CV] C=0.05, penalty=l2 ..............................................\n",
      "[CV] C=0.05, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.05, penalty=l1, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ............................... C=0.05, penalty=l1, total=   0.1s\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.0s\n",
      "[CV] C=0.5, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.1s\n",
      "[CV] C=0.5, penalty=l1 ...............................................\n",
      "[CV] ............................... C=0.05, penalty=l2, total=   0.1s\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of  18 | elapsed:    0.1s remaining:    0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................ C=0.5, penalty=l1, total=   0.2s\n",
      "[CV] ............................... C=0.05, penalty=l2, total=   0.3s\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.3s\n",
      "[CV] ............................... C=0.05, penalty=l2, total=   0.3s\n",
      "[CV] C=0.5, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.5, penalty=l1, total=   0.2s\n",
      "[CV] C=0.5, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.2s\n",
      "[CV] C=0.5, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.5, penalty=l2, total=   0.1s\n",
      "[CV] C=0.5, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.5, penalty=l2, total=   0.1s\n",
      "[CV] ................................ C=0.5, penalty=l2, total=   0.1s\n",
      "[CV] ................................ C=0.5, penalty=l1, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  13 out of  18 | elapsed:    0.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "penalty = ['l1', 'l2']\n",
    "C = [0.05, 0.1, 0.5]\n",
    "\n",
    "param_grid = dict(penalty=penalty, \n",
    "                  C=C)\n",
    "\n",
    "lr_stacking = GridSearchCV(LogisticRegression(), param_grid, n_jobs=-1, scoring = 'neg_log_loss', verbose = 2)\n",
    "grid_search_results_blending = lr_stacking.fit(preds_table,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.20247563088362186\n",
      "{'C': 0.5, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_results_blending.best_score_)\n",
    "print(grid_search_results_blending.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_blending = LogisticRegression(penalty='l1',\n",
    "                                 solver='liblinear',\n",
    "                                 C=0.5,\n",
    "                                 verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_blending.fit(preds_table, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prédictions sur les données de test en csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Feature engineering sur le fichier test.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"weekday\"] = test[\"hour\"].apply(lambda x: datetime.strptime(str(x), '%y%m%d%H').weekday())\n",
    "test[\"hour\"] = test[\"hour\"].apply(lambda x: int(str(x)[-2:]))\n",
    "test[\"area\"] = test[\"C15\"] * test[\"C16\"]\n",
    "\n",
    "test['User_freq'] = test['device_id'] + test['device_ip'] + test['device_model'] #on crée une feature user \n",
    "values = test['User_freq'].value_counts() # on remplace la valeur de user par sa fréquence d'apparition\n",
    "test['User_freq'] = test['User_freq'].apply(lambda row: values[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = test[['C1', 'hour', 'banner_pos', 'site_category', 'app_category', 'device_type', 'device_conn_type', 'C14','C15', 'C16', 'C17', 'C18', \n",
    "           'C19', 'C20','C21', 'area', 'weekday', 'User_freq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['C20'] = test['C20'].replace(-1, np.nan)\n",
    "test['C20'] = test['C20'].replace(np.nan, X['C20'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in columns_to_encode:\n",
    "    test[col] = test[col].astype('category',categories = df_full_columns[col].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test, columns=columns_to_encode, prefix = columns_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4577464, 94)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 94)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_preds_test = lr.predict_proba(test)\n",
    "xgb_preds_test = xgb.predict_proba(test)\n",
    "rf_preds_test = rf.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_table_final = pd.DataFrame({\"LR\":lr_preds_test[:,1], \"XGBoost\":xgb_preds_test[:,1], \"RandomForests\":rf_preds_test[:,1]}, index=test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Export pour test Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = lr_blending.predict_proba(preds_table_final)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preds = pd.DataFrame(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_file = pd.read_csv(\"sampleSubmission.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_file['click'] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas d'un export en .gz :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_file.to_csv(path_or_buf= './submission_files/preds_' + datetime.now().strftime(\"%d%m%Y-%H%M%S\") + '.gz', index = False, sep = ',', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
